import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score
import pickle
import warnings
warnings.filterwarnings('ignore')

# 1. åŠ è½½çœŸå®çš„å­¦ç”Ÿæˆç»©æ•°æ®é›†
def load_student_data():
    """åŠ è½½student_data_adjusted_rounded.csvæ–‡ä»¶å¹¶è¿›è¡Œé¢„å¤„ç†"""
    try:
        # è¯»å–CSVæ–‡ä»¶ï¼ˆè‡ªåŠ¨é€‚é…å¸¸è§ç¼–ç ï¼‰
        df = pd.read_csv('student_data_adjusted_rounded.csv', encoding='utf-8')
        print(f"âœ… æˆåŠŸåŠ è½½æ•°æ®ï¼Œæ•°æ®å½¢çŠ¶ï¼š{df.shape}")
        print(f"\næ•°æ®åˆ—åï¼š{df.columns.tolist()}")
        print(f"\næ•°æ®å‰5è¡Œï¼š\n{df.head()}")
        
        # åŸºæœ¬æ•°æ®æ¸…æ´—
        # åˆ é™¤ç©ºå€¼è¡Œ
        df = df.dropna()
        # é‡ç½®ç´¢å¼•
        df = df.reset_index(drop=True)
        
        # æ¸…ç†åˆ—åä¸­çš„ç©ºæ ¼ï¼ˆå…³é”®ä¿®å¤ï¼šè§£å†³"ä½œä¸šå®Œæˆ ç‡"çš„ç©ºæ ¼é—®é¢˜ï¼‰
        df.columns = df.columns.str.strip()
        
        return df
    except FileNotFoundError:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°student_data_adjusted_rounded.csvæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ï¼")
        raise
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å‡ºé”™ï¼š{str(e)}")
        raise

# 2. æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹
def preprocess_data(df):
    """æ•°æ®é¢„å¤„ç†ï¼Œç”Ÿæˆæ¨¡å‹æ‰€éœ€çš„ç‰¹å¾å’Œç›®æ ‡å˜é‡"""
    # å®šä¹‰æ ¸å¿ƒç‰¹å¾åˆ—ï¼ˆæ‰©å±•å…³é”®è¯ï¼Œé€‚é…ä½ çš„å®é™…åˆ—åï¼‰
    feature_mapping = {
        'å­¦ä¹ æ—¶é•¿': ['æ¯å‘¨å­¦ä¹ æ—¶é•¿ï¼ˆå°æ—¶ï¼‰', 'å­¦ä¹ æ—¶é•¿', 'study_hours', 'hours_studied'],
        'å‡ºå‹¤ç‡': ['ä¸Šè¯¾å‡ºå‹¤ç‡', 'å‡ºå‹¤ç‡', 'attendance', 'attendance_rate'],
        'æœŸä¸­æˆç»©': ['æœŸä¸­è€ƒè¯•åˆ†æ•°', 'æœŸä¸­æˆç»©', 'midterm_score', 'midterm'],
        'ä½œä¸šå®Œæˆç‡': ['ä½œä¸šå®Œæˆç‡', 'homework', 'homework_rate'],
        'ä¸“ä¸š': ['ä¸“ä¸š', 'major', 'department'],
        'æ€§åˆ«': ['æ€§åˆ«', 'gender', 'sex'],
        'æœŸæœ«æˆç»©': ['æœŸæœ«è€ƒè¯•åˆ†æ•°', 'æœŸæœ«æˆç»©', 'final_score', 'final_grade', 'æœŸæœ«åˆ†æ•°']  # å…³é”®ä¿®å¤ï¼šæ·»åŠ "æœŸæœ«è€ƒè¯•åˆ†æ•°"
    }
    
    # è‡ªåŠ¨åŒ¹é…å®é™…åˆ—åï¼ˆç»Ÿä¸€è½¬ä¸ºå°å†™ï¼Œå»é™¤ç©ºæ ¼ååŒ¹é…ï¼‰
    cols_clean = [col.strip().lower() for col in df.columns]
    selected_cols = {}
    
    for key, possible_names in feature_mapping.items():
        for name in possible_names:
            # å°†å€™é€‰åä¹Ÿæ¸…ç†ååŒ¹é…
            name_clean = name.strip().lower()
            if name_clean in cols_clean:
                # æ‰¾åˆ°åŒ¹é…çš„åŸå§‹åˆ—å
                original_idx = cols_clean.index(name_clean)
                original_col = df.columns[original_idx]
                selected_cols[key] = original_col
                break
    
    print(f"\nâœ… åŒ¹é…åˆ°çš„åˆ—åï¼š{selected_cols}")
    
    # æå–ç‰¹å¾å’Œç›®æ ‡å˜é‡
    # æ•°å€¼ç‰¹å¾
    numeric_features = []
    for key in ['å­¦ä¹ æ—¶é•¿', 'å‡ºå‹¤ç‡', 'æœŸä¸­æˆç»©', 'ä½œä¸šå®Œæˆç‡']:
        if key in selected_cols:
            numeric_features.append(selected_cols[key])
    
    # åˆ†ç±»ç‰¹å¾
    categorical_features = []
    for key in ['ä¸“ä¸š', 'æ€§åˆ«']:
        if key in selected_cols:
            categorical_features.append(selected_cols[key])
    
    # ç›®æ ‡å˜é‡ï¼ˆå…³é”®ä¿®å¤ï¼šä¸¥æ ¼æ£€æŸ¥ï¼‰
    if 'æœŸæœ«æˆç»©' not in selected_cols:
        # å…œåº•ï¼šç›´æ¥æ£€æŸ¥æ˜¯å¦åŒ…å«"æœŸæœ«"å…³é”®è¯çš„åˆ—
        final_cols = [col for col in df.columns if 'æœŸæœ«' in col]
        if final_cols:
            selected_cols['æœŸæœ«æˆç»©'] = final_cols[0]
            print(f"âš ï¸ è‡ªåŠ¨å…œåº•åŒ¹é…æœŸæœ«æˆç»©åˆ—ï¼š{final_cols[0]}")
        else:
            raise ValueError("âŒ æ•°æ®ä¸­æœªæ‰¾åˆ°æœŸæœ«æˆç»©ç›¸å…³åˆ—ï¼Œè¯·æ£€æŸ¥æ•°æ®åˆ—åï¼")
    target_col = selected_cols['æœŸæœ«æˆç»©']
    
    # æ„å»ºç‰¹å¾çŸ©é˜µ
    X_numeric = df[numeric_features].astype(float)
    X_categorical = pd.get_dummies(df[categorical_features], drop_first=True)
    X = pd.concat([X_numeric, X_categorical], axis=1)
    y = df[target_col].astype(float)
    
    print(f"\nâœ… ç‰¹å¾çŸ©é˜µå½¢çŠ¶ï¼š{X.shape}")
    print(f"âœ… ç›®æ ‡å˜é‡å½¢çŠ¶ï¼š{y.shape}")
    print(f"\nç‰¹å¾åˆ—åï¼š{X.columns.tolist()}")
    
    return X, y, X.columns.tolist()

# 3. è®­ç»ƒæ¨¡å‹å¹¶ä¿å­˜
def train_and_save_model():
    """è®­ç»ƒéšæœºæ£®æ—å›å½’æ¨¡å‹å¹¶ä¿å­˜"""
    # åŠ è½½æ•°æ®
    df = load_student_data()
    
    # é¢„å¤„ç†
    X, y, feature_names = preprocess_data(df)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # è®­ç»ƒæ¨¡å‹
    print("\nğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    model = RandomForestRegressor(
        n_estimators=100,
        max_depth=10,
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train)
    
    # è¯„ä¼°æ¨¡å‹
    y_pred = model.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    print(f"\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print(f"ğŸ“Š æ¨¡å‹RÂ²å¾—åˆ†ï¼š{r2:.4f} (è¶Šæ¥è¿‘1è¶Šå¥½)")
    
    # ä¿å­˜æ¨¡å‹å’Œç‰¹å¾å
    with open('score_prediction_model.pkl', 'wb') as f:
        pickle.dump(model, f)
    
    with open('feature_names.pkl', 'wb') as f:
        pickle.dump(feature_names, f)
    
    # ä¿å­˜æ•°æ®åˆ—åæ˜ å°„ï¼ˆç”¨äºé¢„æµ‹æ—¶åŒ¹é…ï¼‰
    df_columns = df.columns.tolist()
    with open('data_columns.pkl', 'wb') as f:
        pickle.dump(df_columns, f)
    
    print("\nğŸ“ å·²ä¿å­˜æ–‡ä»¶ï¼š")
    print("   - score_prediction_model.pkl (é¢„æµ‹æ¨¡å‹)")
    print("   - feature_names.pkl (ç‰¹å¾åˆ—å)")
    print("   - data_columns.pkl (æ•°æ®åˆ—å)")
    
    return model

# æ‰§è¡Œè®­ç»ƒ
if __name__ == "__main__":
    train_and_save_model()
